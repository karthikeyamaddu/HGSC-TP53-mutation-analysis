{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FafxL1ys_4Wq",
        "outputId": "3e932ae6-a19f-4049-c314-28625c244873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q xgboost scikit-learn pandas streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7HaD1I6AQLQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# 1) Load a FASTA (.fna) file into one string\n",
        "def load_fna(path):\n",
        "    with open(path, 'r') as f:\n",
        "        return ''.join(line.strip() for line in f if not line.startswith('>'))\n",
        "\n",
        "# 2) Sliding‚Äëwindow augmentation\n",
        "def augment_and_vectorize(seqs, k=6, window=300, step=150, stride=1):\n",
        "    X_dicts, y = [], []\n",
        "    for gene, seq in seqs.items():\n",
        "        for i in range(0, len(seq) - window + 1, step):\n",
        "            sub = seq[i:i+window]\n",
        "            kmers = [sub[j:j+k] for j in range(0, len(sub)-k+1, stride)]\n",
        "            X_dicts.append(dict(Counter(kmers)))\n",
        "            y.append([gene])\n",
        "    return X_dicts, y\n",
        "\n",
        "# 3) Full‚Äësequence (‚Äúnew logic‚Äù) vectorization\n",
        "def fullseq_vectorize(seqs, k=6):\n",
        "    X_dicts, y = [], []\n",
        "    for gene, seq in seqs.items():\n",
        "        kmers = [seq[i:i+k] for i in range(len(seq)-k+1)]\n",
        "        X_dicts.append(dict(Counter(kmers)))\n",
        "        y.append([gene])\n",
        "    return X_dicts, y\n",
        "\n",
        "# 4) Your gene files (in the notebook‚Äôs working directory)\n",
        "gene_files = {\n",
        "    'TP53':  'tp53.fna',\n",
        "    'BRCA1': 'brca1.fna',\n",
        "    'BRCA2': 'brca2.fna',\n",
        "    'STK11': 'stk11.fna',\n",
        "    'CDH1':  'cdh1.fna'\n",
        "}\n",
        "\n",
        "# Read sequences\n",
        "gene_seqs = {g: load_fna(fname) for g, fname in gene_files.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GayvhtXeAZ1Z",
        "outputId": "3d5a0a56-99e6-4440-f2a4-fe023300b815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline shapes: (4677, 4093) (4677, 5)\n",
            "=== Baseline Results ===\n",
            "\n",
            "LogisticRegression Accuracy: 0.9154, F1: 0.9502\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.96      0.93      0.95       427\n",
            "       BRCA2       0.94      0.95      0.95       274\n",
            "        CDH1       0.97      0.94      0.95       313\n",
            "       STK11       1.00      0.95      0.98        84\n",
            "        TP53       1.00      0.92      0.96        72\n",
            "\n",
            "   micro avg       0.96      0.94      0.95      1170\n",
            "   macro avg       0.97      0.94      0.96      1170\n",
            "weighted avg       0.96      0.94      0.95      1170\n",
            " samples avg       0.93      0.94      0.93      1170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NaiveBayes Accuracy: 0.2752, F1: 0.6303\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.50      0.93      0.65       427\n",
            "       BRCA2       0.42      0.98      0.59       274\n",
            "        CDH1       0.39      0.96      0.55       313\n",
            "       STK11       1.00      0.88      0.94        84\n",
            "        TP53       0.91      1.00      0.95        72\n",
            "\n",
            "   micro avg       0.47      0.95      0.63      1170\n",
            "   macro avg       0.64      0.95      0.74      1170\n",
            "weighted avg       0.51      0.95      0.65      1170\n",
            " samples avg       0.55      0.95      0.67      1170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RandomForest Accuracy: 0.8060, F1: 0.8917\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.99      0.84      0.91       427\n",
            "       BRCA2       1.00      0.83      0.91       274\n",
            "        CDH1       1.00      0.80      0.89       313\n",
            "       STK11       1.00      0.80      0.89        84\n",
            "        TP53       1.00      0.53      0.69        72\n",
            "\n",
            "   micro avg       1.00      0.81      0.89      1170\n",
            "   macro avg       1.00      0.76      0.86      1170\n",
            "weighted avg       1.00      0.81      0.89      1170\n",
            " samples avg       0.81      0.81      0.81      1170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP Accuracy: 0.9427, F1: 0.9672\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.98      0.96      0.97       427\n",
            "       BRCA2       0.96      0.96      0.96       274\n",
            "        CDH1       0.98      0.94      0.96       313\n",
            "       STK11       1.00      0.95      0.98        84\n",
            "        TP53       1.00      0.97      0.99        72\n",
            "\n",
            "   micro avg       0.98      0.96      0.97      1170\n",
            "   macro avg       0.98      0.96      0.97      1170\n",
            "weighted avg       0.98      0.96      0.97      1170\n",
            " samples avg       0.95      0.96      0.95      1170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:35:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:36:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:36:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:36:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:36:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBoost Accuracy: 0.8880, F1: 0.9357\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.97      0.91      0.94       427\n",
            "       BRCA2       0.99      0.92      0.95       274\n",
            "        CDH1       0.97      0.89      0.93       313\n",
            "       STK11       1.00      0.95      0.98        84\n",
            "        TP53       1.00      0.65      0.79        72\n",
            "\n",
            "   micro avg       0.98      0.90      0.94      1170\n",
            "   macro avg       0.99      0.87      0.92      1170\n",
            "weighted avg       0.98      0.90      0.93      1170\n",
            " samples avg       0.89      0.90      0.89      1170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# 1) Augment + vectorize\n",
        "Xb_dicts, yb_raw = augment_and_vectorize(gene_seqs,\n",
        "                                         k=6, window=300, step=150, stride=1)\n",
        "\n",
        "# 2) Vectorizer & MultiLabelBinarizer\n",
        "vec_base = DictVectorizer(sparse=False)\n",
        "Xb = vec_base.fit_transform(Xb_dicts)\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "Yb = mlb.fit_transform(yb_raw)\n",
        "\n",
        "print(\"Baseline shapes:\", Xb.shape, Yb.shape)\n",
        "\n",
        "# 3) Split\n",
        "Xb_tr, Xb_te, Yb_tr, Yb_te = train_test_split(\n",
        "    Xb, Yb, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# 4) Models\n",
        "models = {\n",
        "    'LogisticRegression': MultiOutputClassifier(LogisticRegression(max_iter=200, random_state=42)),\n",
        "    'NaiveBayes':         MultiOutputClassifier(GaussianNB()),\n",
        "    'RandomForest':       MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    'MLP':                MultiOutputClassifier(MLPClassifier(hidden_layer_sizes=(128,64),\n",
        "                                                               max_iter=300, random_state=42)),\n",
        "    'XGBoost':            MultiOutputClassifier(XGBClassifier(eval_metric='logloss',\n",
        "                                                               use_label_encoder=False,\n",
        "                                                               random_state=42))\n",
        "}\n",
        "\n",
        "# 5) Train & evaluate\n",
        "print(\"=== Baseline Results ===\")\n",
        "for name, mdl in models.items():\n",
        "    mdl.fit(Xb_tr, Yb_tr)\n",
        "    pred = mdl.predict(Xb_te)\n",
        "    print(f\"\\n{name} Accuracy: {accuracy_score(Yb_te, pred):.4f}, F1: {f1_score(Yb_te, pred, average='micro'):.4f}\")\n",
        "    print(classification_report(Yb_te, pred, target_names=mlb.classes_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIKQ-j4LuGz2"
      },
      "source": [
        "better trainiing logic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmISNSGiAjcH",
        "outputId": "32009c99-20bd-4b84-a1b1-980a7f426495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LogisticRegression...\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "LogisticRegression best params ‚Üí {'clf__estimator__C': 1}\n",
            "LogisticRegression training time: 70.41 seconds\n",
            "\n",
            "Training GaussianNB...\n",
            "GaussianNB training time: 1.25 seconds\n",
            "\n",
            "Training RandomForest...\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "RandomForest best params ‚Üí {'clf__estimator__n_estimators': 100}\n",
            "RandomForest training time: 33.01 seconds\n",
            "\n",
            "Training XGBoost...\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "XGBoost best params ‚Üí {'clf__estimator__max_depth': 5, 'clf__estimator__n_estimators': 100}\n",
            "XGBoost training time: 37.56 seconds\n",
            "\n",
            "Training MLP...\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "MLP best params ‚Üí {'clf__estimator__alpha': 0.0001}\n",
            "MLP training time: 81.98 seconds\n",
            "\n",
            "LogisticRegression Evaluation:\n",
            "F1 Score (micro): 0.9687002652519894\n",
            "Accuracy: 0.9444444444444444\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.96      0.96      0.96       342\n",
            "       BRCA2       0.94      0.99      0.96       210\n",
            "        CDH1       0.96      0.98      0.97       253\n",
            "       STK11       1.00      1.00      1.00        68\n",
            "        TP53       1.00      0.98      0.99        63\n",
            "\n",
            "   micro avg       0.96      0.98      0.97       936\n",
            "   macro avg       0.97      0.98      0.98       936\n",
            "weighted avg       0.96      0.98      0.97       936\n",
            " samples avg       0.96      0.98      0.97       936\n",
            "\n",
            "\n",
            "GaussianNB Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (micro): 0.6091915464609191\n",
            "Accuracy: 0.22008547008547008\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.46      0.95      0.62       342\n",
            "       BRCA2       0.40      0.99      0.57       210\n",
            "        CDH1       0.36      1.00      0.53       253\n",
            "       STK11       1.00      0.90      0.95        68\n",
            "        TP53       0.93      1.00      0.96        63\n",
            "\n",
            "   micro avg       0.44      0.97      0.61       936\n",
            "   macro avg       0.63      0.97      0.73       936\n",
            "weighted avg       0.49      0.97      0.63       936\n",
            " samples avg       0.52      0.97      0.65       936\n",
            "\n",
            "\n",
            "RandomForest Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (micro): 0.9181084198385236\n",
            "Accuracy: 0.8504273504273504\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.99      0.91      0.95       342\n",
            "       BRCA2       1.00      0.88      0.94       210\n",
            "        CDH1       1.00      0.82      0.90       253\n",
            "       STK11       1.00      0.88      0.94        68\n",
            "        TP53       1.00      0.54      0.70        63\n",
            "\n",
            "   micro avg       1.00      0.85      0.92       936\n",
            "   macro avg       1.00      0.81      0.88       936\n",
            "weighted avg       1.00      0.85      0.92       936\n",
            " samples avg       0.85      0.85      0.85       936\n",
            "\n",
            "\n",
            "XGBoost Evaluation:\n",
            "F1 Score (micro): 0.9466666666666667\n",
            "Accuracy: 0.9038461538461539\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.98      0.92      0.95       342\n",
            "       BRCA2       0.98      0.95      0.97       210\n",
            "        CDH1       0.99      0.88      0.93       253\n",
            "       STK11       1.00      1.00      1.00        68\n",
            "        TP53       1.00      0.73      0.84        63\n",
            "\n",
            "   micro avg       0.99      0.91      0.95       936\n",
            "   macro avg       0.99      0.90      0.94       936\n",
            "weighted avg       0.99      0.91      0.95       936\n",
            " samples avg       0.91      0.91      0.91       936\n",
            "\n",
            "\n",
            "MLP Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (micro): 0.9655172413793104\n",
            "Accuracy: 0.9401709401709402\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       BRCA1       0.98      0.96      0.97       342\n",
            "       BRCA2       0.96      0.96      0.96       210\n",
            "        CDH1       0.97      0.96      0.97       253\n",
            "       STK11       1.00      1.00      1.00        68\n",
            "        TP53       1.00      0.89      0.94        63\n",
            "\n",
            "   micro avg       0.97      0.96      0.97       936\n",
            "   macro avg       0.98      0.95      0.97       936\n",
            "weighted avg       0.97      0.96      0.97       936\n",
            " samples avg       0.95      0.96      0.95       936\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "\n",
        "# --- 1) k-mer feature extractor ---\n",
        "def load_data(gene_sequences, k=6, window=300, step=150):\n",
        "    X_dict, y_raw = [], []\n",
        "    for gene, seq in gene_sequences.items():\n",
        "        for i in range(0, len(seq) - window + 1, step):\n",
        "            sub = seq[i:i + window]\n",
        "            kmers = [sub[j:j + k] for j in range(window - k + 1)]\n",
        "            X_dict.append(dict(Counter(kmers)))\n",
        "            y_raw.append([gene])\n",
        "    return X_dict, y_raw\n",
        "\n",
        "# --- 2) Data prep ---\n",
        "X_dict, y_raw = load_data(gene_seqs)\n",
        "vectorizer = DictVectorizer(sparse=False)\n",
        "X = vectorizer.fit_transform(X_dict)\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y = mlb.fit_transform(y_raw)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "def make_pipeline(estimator):\n",
        "    return Pipeline([\n",
        "        ('scale', StandardScaler()),\n",
        "        ('clf', MultiOutputClassifier(estimator))\n",
        "    ])\n",
        "\n",
        "# --- 3) Models and param grids ---\n",
        "models = {\n",
        "    'LogisticRegression': make_pipeline(LogisticRegression(max_iter=300, solver='liblinear')),\n",
        "    'GaussianNB':         make_pipeline(GaussianNB()),\n",
        "    'RandomForest':       make_pipeline(RandomForestClassifier(n_jobs=-1, random_state=42)),\n",
        "    'XGBoost':            make_pipeline(XGBClassifier(eval_metric='logloss', n_jobs=-1, random_state=42)),\n",
        "    'MLP':                make_pipeline(MLPClassifier(hidden_layer_sizes=(128,), max_iter=300, early_stopping=True, random_state=42))\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'LogisticRegression': {'clf__estimator__C': [1]},\n",
        "    'RandomForest':       {'clf__estimator__n_estimators': [100]},\n",
        "    'XGBoost':            {'clf__estimator__n_estimators': [100], 'clf__estimator__max_depth': [5]},\n",
        "    'MLP':                {'clf__estimator__alpha': [1e-4]}\n",
        "}\n",
        "\n",
        "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
        "trained_models = {}\n",
        "\n",
        "# --- 4) Training ---\n",
        "for name, pipeline in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    start = time.time()\n",
        "\n",
        "    if name in param_grids:\n",
        "        grid = GridSearchCV(pipeline, param_grids[name], cv=kf, scoring='f1_micro', n_jobs=-1, verbose=1)\n",
        "        grid.fit(X_train, Y_train)\n",
        "        trained_models[name] = grid.best_estimator_\n",
        "        print(f\"{name} best params ‚Üí\", grid.best_params_)\n",
        "    else:\n",
        "        pipeline.fit(X_train, Y_train)\n",
        "        trained_models[name] = pipeline\n",
        "\n",
        "    print(f\"{name} training time: {time.time() - start:.2f} seconds\")\n",
        "\n",
        "# --- 5) Evaluation ---\n",
        "def evaluate_model(name, model, X_test, Y_test):\n",
        "    print(f\"\\n{name} Evaluation:\")\n",
        "    Y_pred = model.predict(X_test)\n",
        "    print(\"F1 Score (micro):\", f1_score(Y_test, Y_pred, average='micro'))\n",
        "    print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(Y_test, Y_pred, target_names=mlb.classes_))\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    evaluate_model(name, model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XTB155SChbk",
        "outputId": "69b4fec7-6bdc-417c-ede3-521e9313ca07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Baseline model: LogisticRegression\n",
            "Saving Baseline model: GaussianNB\n",
            "Saving Baseline model: RandomForest\n",
            "Saving Baseline model: XGBoost\n",
            "Saving Baseline model: MLP\n",
            "Saving New Logic model: LogisticRegression\n",
            "Saving New Logic model: GaussianNB\n",
            "Saving New Logic model: RandomForest\n",
            "Saving New Logic model: XGBoost\n",
            "Saving New Logic model: MLP\n",
            "‚úÖ Saved vectorizers, mlb, and all models.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Make directories\n",
        "os.makedirs('base_line_model', exist_ok=True)\n",
        "os.makedirs('new_logic', exist_ok=True)\n",
        "\n",
        "# --- Save vectorizers and binarizer ---\n",
        "pickle.dump(vec_base, open('base_line_model/vec_base.pkl', 'wb'))\n",
        "pickle.dump(vectorizer, open('new_logic/vec_new.pkl', 'wb'))\n",
        "pickle.dump(mlb, open('base_line_model/mlb.pkl', 'wb'))  # shared mlb\n",
        "\n",
        "# --- Retrain and save Baseline Models ---\n",
        "for name, model in models.items():\n",
        "    print(f\"Saving Baseline model: {name}\")\n",
        "    model.fit(Xb, Yb)\n",
        "    with open(f'base_line_model/{name}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "# --- Retrain and save New Logic Models ---\n",
        "for name, model in trained_models.items():\n",
        "    print(f\"Saving New Logic model: {name}\")\n",
        "    model.fit(X, Y)  # Full new logic data\n",
        "    with open(f'new_logic/{name}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "print(\"‚úÖ Saved vectorizers, mlb, and all models.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WtbsHxuAoQ-",
        "outputId": "91a93d15-5b82-4733-f092-19d3b88ad5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Load vectorizers and models\n",
        "vec_base = pickle.load(open('base_line_model/vec_base.pkl', 'rb'))\n",
        "vec_new  = pickle.load(open('new_logic/vec_new.pkl', 'rb'))\n",
        "mlb      = pickle.load(open('base_line_model/mlb.pkl', 'rb'))\n",
        "\n",
        "models_base = {name: pickle.load(open(f'base_line_model/{name}.pkl', 'rb'))\n",
        "               for name in ['LogisticRegression', 'GaussianNB', 'RandomForest', 'MLP', 'XGBoost']}\n",
        "models_new  = {name: pickle.load(open(f'new_logic/{name}.pkl', 'rb'))\n",
        "               for name in ['LogisticRegression', 'GaussianNB', 'RandomForest', 'MLP', 'XGBoost']}\n",
        "\n",
        "st.set_page_config(page_title=\"HGSC Disease predictor\", layout=\"wide\")\n",
        "st.title(\"üî¨ Gene Multi‚ÄëLabel Classifier using k-mer + ML Models\")\n",
        "\n",
        "st.markdown(\"Enter a DNA sequence (A/C/G/T) to predict gene mutations using different models.\")\n",
        "\n",
        "seq = st.text_area(\"üß¨ Paste DNA Sequence Below\", height=150)\n",
        "\n",
        "def kmer_freqs(seq, k=6):\n",
        "    return dict(Counter(seq[i:i+k] for i in range(len(seq) - k + 1)))\n",
        "\n",
        "def predict_all_models(seq, vec, models, label, threshold=2):\n",
        "    freqs = kmer_freqs(seq, k=6)\n",
        "    X_vec = vec.transform([freqs])\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        y_pred = model.predict(X_vec)[0]\n",
        "        genes = mlb.classes_\n",
        "        gene_results = dict(zip(genes, y_pred.astype(int)))\n",
        "        gene_results['HGSC'] = int(y_pred.sum() >= threshold)\n",
        "        gene_results['Confidence'] = round(y_pred.sum() / len(genes), 3)\n",
        "        gene_results['Model'] = name\n",
        "        gene_results['Type'] = label\n",
        "        results.append(gene_results)\n",
        "    return results\n",
        "\n",
        "if st.button(\"üîç Classify Sequence\"):\n",
        "    s = seq.strip().upper().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
        "    if len(s) < 6:\n",
        "        st.error(\"Sequence too short. Please input at least 6 base pairs.\")\n",
        "    else:\n",
        "        with st.spinner(\"Running predictions...\"):\n",
        "            base_results = predict_all_models(s, vec_base, models_base, \"Baseline\")\n",
        "            new_results  = predict_all_models(s, vec_new, models_new, \"New Logic\")\n",
        "\n",
        "            df_all = pd.DataFrame(base_results + new_results)\n",
        "\n",
        "            st.subheader(\"üìä Classification Results Table\")\n",
        "            st.dataframe(df_all.set_index(['Type', 'Model']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTwEtycoAqEs",
        "outputId": "e541d5d4-cde5-4730-f752-8c64dd7a3d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Public URL: NgrokTunnel: \"https://e395-34-19-31-243.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Kill any existing process\n",
        "!fuser -k 8501/tcp\n",
        "\n",
        "# Set your new working ngrok token\n",
        "ngrok.set_auth_token  (\"2xHG91dZ6Zfk4XVbkg12NjsNzuw_5nn4kfz7PznQYtnTf1KKy\")\n",
        "\n",
        "# Start Streamlit in background\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n",
        "# Wait for the server to boot up\n",
        "time.sleep(10)\n",
        "\n",
        "# Create public URL\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üîó Public URL:\", public_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the models\n"
      ],
      "metadata": {
        "id": "3kaWllh229It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Paths to the folders\n",
        "folder_path1 = '/content/base_line_model'\n",
        "folder_path2 = '/content/new_logic'\n",
        "\n",
        "# Names for the zip files\n",
        "zip_filename1 = 'base_line_model.zip'\n",
        "zip_filename2 = 'new_logic.zip'\n",
        "\n",
        "# Zip and download the first folder\n",
        "shutil.make_archive(zip_filename1.replace('.zip', ''), 'zip', folder_path1)\n",
        "files.download(zip_filename1)\n",
        "\n",
        "# Zip and download the second folder\n",
        "shutil.make_archive(zip_filename2.replace('.zip', ''), 'zip', folder_path2)\n",
        "files.download(zip_filename2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tdpGAfgD28kP",
        "outputId": "27483566-42b5-4340-8d77-30988f205c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_725cf940-5373-4cb6-9d4d-cd5c6df8edd3\", \"base_line_model.zip\", 67535705)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1427ab70-a902-4303-9462-978d63cbca66\", \"new_logic.zip\", 67482065)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
